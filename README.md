系统架构
1数据存储：使用文本文件 data.txt 作为知识源，存储各种问题及其答案。这些数据可以是不同领域的信息，如历史、科学、技术等。
2模型选择：使用 OpenAI 的语言模型（通过 langchain库）来处理问答逻辑。同时，也有本地模型（如 transformers库中的 AutoModelForCausalLM）作为替代方案。
实现方式
Demo 1 - OpenAI Key 实现问答：
流程：用户输入问题，系统通过 OpenAI API（使用 OpenAI key）查询 data.txt 中是否有匹配的问题。如果有匹配的问题，返回相应答案；如果没有匹配的问题，则提示用户无法回答。
Demo 2 - 推断回答：
流程：当用户输入问题且 data.txt 中没有匹配的答案时，利用 OpenAI 模型的推断能力生成回答。这需要模型对问题进行理解和推理，尝试生成一个合理的答案。
Demo 3 - Google 检索回答：
流程：通过 Google 搜索 API（使用 Google API key）检索相关信息来回答用户问题。当 data.txt 中没有匹配答案时，系统将用户问题发送到 Google 搜索，获取搜索结果并从中提取相关信息作为回答。
Demo 4 - 使用本地模型：
流程：使用本地模型（如 transformers库中的 AutoModelForCausalLM）来回答问题。用户输入问题后，系统将问题传递给本地模型，模型根据自身的知识和推理能力生成回答。
总结
这个问答系统通过不同方式实现了多种功能，利用 OpenAI key、推断、Google 检索以及本地模型来满足用户的不同需求。每个 demo 都有其独特的优势和适用场景，用户可以根据实际情况选择合适的方式来获取答案。
